{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN0VeUzNBSuDaFOo14mWO8f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TgIymgEfyRvt"},"outputs":[],"source":["# Import the required modules and libraries:\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms"]},{"cell_type":"code","source":["# Resize the size of all images to a unanimous value (224, 224).\n","# Convert PIL image objects into Tensors.\n","# Normalize the tensor values based on the mean and standard deviation of the RGB values of all the images:\n","\n","\n","data_transforms = transforms.Compose([\n","transforms.Resize((224,224)),\n","transforms.RandomHorizontalFlip(),\n","transforms.ToTensor(),\n","transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])"],"metadata":{"id":"FGSP2LTtyf4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an object of torchvision.datasets.CIFAR100 to get the training and testing set:\n","\n","trainset = datasets.CIFAR100(root = \"/content/drive/MyDrive/5_Cisc442_CompVision/PR2\", train = True, transform = data_transforms, download=True)\n","testset = datasets.CIFAR100(root = \"/content/drive/MyDrive/5_Cisc442_CompVision/PR2\", train=False, transform = data_transforms, download=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNmEMRzGzAmE","executionInfo":{"status":"ok","timestamp":1699487885122,"user_tz":300,"elapsed":6615,"user":{"displayName":"Mycah Detorres","userId":"17861309304446548174"}},"outputId":"6a100bbf-0979-4a1e-958a-f076524e13cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /content/drive/MyDrive/5_Cisc442_CompVision/PR2/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169001437/169001437 [00:01<00:00, 90571355.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/drive/MyDrive/5_Cisc442_CompVision/PR2/cifar-100-python.tar.gz to /content/drive/MyDrive/5_Cisc442_CompVision/PR2\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Create a data loader.\n","\n","data = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n","dataTestSet = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True)"],"metadata":{"id":"hTfFx6a1zQYb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load a VGG16 network with pretrained ImageNet weights:\n","\n","model = models.vgg16(pretrained = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgF3YklKzURg","executionInfo":{"status":"ok","timestamp":1699487897555,"user_tz":300,"elapsed":6406,"user":{"displayName":"Mycah Detorres","userId":"17861309304446548174"}},"outputId":"28d7eaa1-6b61-4c84-8cd5-3d83b4d91647"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:04<00:00, 120MB/s]\n"]}]},{"cell_type":"code","source":["# Extract the number of input features for the last fully connected layer of the model:\n","\n","num_in_ftrs = model.classifier[6].in_features"],"metadata":{"id":"VO6kku5azXd-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace the last fully connected layer with a new layer.\n","# The new layer has the same number of input features as the\n","# original network but the number of outputs should be\n","# equal to the number of classes in the CIFAR100 dataset.\n","\n","num_cls = len(trainset.classes) # number of classes in the CIFAR100 dataset\n","model.classifier[6] = nn.Linear(num_in_ftrs, num_cls) # num_cls is the number of classes."],"metadata":{"id":"Pip3qgNhzbGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We are using pretrained weights from the ImageNet dataset.\n","# The last layer of VGG16 has been replaced for fitting with our dataset (CIFAR100).\n","# Except for the new last layer, weights from other layers need to be frozen.\n","# It means that these weights will not be updated during the training.\n","\n","for param in model.parameters(): # freeze all the layers\n","  param.requires_grad = False\n","for param in model.classifier[6].parameters(): # unfreeze the last linear layer.\n","  param.requires_grad = True"],"metadata":{"id":"V498MuA9zqvA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set the number of epochs:\n","num_epochs = 10"],"metadata":{"id":"uneSL911z0jR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the model to GPU (if available):\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)"],"metadata":{"id":"b2irE7HJz68L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a loss function for evaluating the trained model:\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"s3MOHVLyz8TT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create an optimizer with an initial learning rate and momentum:\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"so6QN00jz9d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a scheduler to control the way that learning rate changes during the training process:\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"],"metadata":{"id":"hWI_BZsaz-_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Iterate over the epochs and save the best model weights.\n","Basically, the best model can achieve the best accuracy during the iteration.\n","In every iteration, we get a mini-batch of images and their corresponding labels.\n","Use zero_grad() to reset the calculated gradients.\n","Use the current model weights for predication and backpropagate the prediction loss.\n","After iterating over all batches and if we are in the training phase, we need to run scheduler.step() to update the scheduler status.\n","\n","So, for each batch, the pseudo-code is:\n","images, labels = data # data is a mini-batch input\n","optimizer.zero_grad()\n","outputs = model(images) # here the model is the pretrained VGG16\n","loss = criterion(outputs, labels)\n","loss.backward()\n","optimizer.step()\n","'''\n","\n","model.train()\n","\n","# Iterate over the epochs and save the best model weights.\n","for i in range(num_epochs):\n","  for batch in data:\n","\n","    # In every iteration, we get a mini-batch of images and their corresponding labels.\n","    # data is a mini-batch input\n","    images, labels = batch # data is a mini-batch input\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Use zero_grad() to reset the calculated gradients.\n","    optimizer.zero_grad()\n","\n","    # Use the current model weights for predication and backpropagate the prediction loss.\n","    outputs = model(images) # here the model is the pretrained VGG16\n","    loss = criterion(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","  # After iterating over all batches and if we are in the training phase, we need to run scheduler.step() to update the scheduler status.\n","  scheduler.step()\n","\n","\n"],"metadata":{"id":"-40G5BTe0C9Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the model weights:\n","torch.save(model.state_dict(), 'best_model.pth')"],"metadata":{"id":"fCd0E6TJ0Mfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The testing process is very similar to the training process except that there is no need to backpropagate the loss.\n","# For testing the model, first, you need to prepare the model in the same way that we prepared it for the\n","# training process and load the best model that we saved in the training process.\n","model.load_state_dict(torch.load('best_model.pth'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDIwXhDs0P36","executionInfo":{"status":"ok","timestamp":1699476018101,"user_tz":300,"elapsed":683,"user":{"displayName":"Mycah Detorres","userId":"17861309304446548174"}},"outputId":"c746f1eb-68e4-4258-b937-5f1a4ccd3dd2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":[],"metadata":{"id":"z6osjwI_qiit"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","After loading the model weights, set the model to evaluation mode.\n","Then go through the test set, and predict the category of images,\n","and compute the number of correctly classified images and the accuracy.\n","\n","So, for each batch, the pseudo-code is:\n","images, labels = data\n","outputs = model(images)\n","_, preds = torch.max(outputs, 1)\n","'''\n","total = 0\n","trues = 0\n","\n","# After loading the model weights, set the model to evaluation mode.\n","model.eval()\n","\n","# Then go through the test set\n","for batch in dataTestSet:\n","  images, labels = batch\n","  images = images.to(device)\n","  labels = labels.to(device)\n","\n","  outputs = model(images)\n","\n","  # predict the category of images\n","  _, preds = torch.max(outputs, 1)\n","\n","  # compute the number of correctly classified images and the accuracy\n","  # correctClassImgs += (outputs == labels).sum().item()\n","  x = torch.eq(labels, preds)\n","  for a in range(len(x)):\n","    total += 1\n","    if x[a] == True:\n","      trues += 1\n","\n","\n","# accuracy = correct / total\n","accuracy = (trues / total)*100\n","\n","# Finally, print the accuracy.\n","print(accuracy)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ka-LoCxO0ZTB","executionInfo":{"status":"ok","timestamp":1699477004374,"user_tz":300,"elapsed":63577,"user":{"displayName":"Mycah Detorres","userId":"17861309304446548174"}},"outputId":"886fb829-1e72-47e7-9f0b-e0a0eff7d175"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["58.96\n"]}]}]}